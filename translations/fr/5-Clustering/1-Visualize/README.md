<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0ab69b161efd7a41d325ee28b29415d7",
  "translation_date": "2025-09-03T22:57:40+00:00",
  "source_file": "5-Clustering/1-Visualize/README.md",
  "language_code": "fr"
}
-->
# Introduction au clustering

Le clustering est un type d'[apprentissage non supervis√©](https://wikipedia.org/wiki/Apprentissage_non_supervis%C3%A9) qui suppose qu'un ensemble de donn√©es est non √©tiquet√© ou que ses entr√©es ne sont pas associ√©es √† des sorties pr√©d√©finies. Il utilise divers algorithmes pour trier les donn√©es non √©tiquet√©es et fournir des regroupements en fonction des motifs qu'il discerne dans les donn√©es.

[![No One Like You par PSquare](https://img.youtube.com/vi/ty2advRiWJM/0.jpg)](https://youtu.be/ty2advRiWJM "No One Like You par PSquare")

> üé• Cliquez sur l'image ci-dessus pour une vid√©o. Pendant que vous √©tudiez l'apprentissage automatique avec le clustering, profitez de quelques morceaux de Dance Hall nig√©rian - voici une chanson tr√®s appr√©ci√©e de 2014 par PSquare.

## [Quiz avant le cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)

### Introduction

Le [clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) est tr√®s utile pour explorer les donn√©es. Voyons s'il peut aider √† d√©couvrir des tendances et des motifs dans la mani√®re dont les audiences nig√©rianes consomment de la musique.

‚úÖ Prenez une minute pour r√©fl√©chir aux utilisations du clustering. Dans la vie quotidienne, le clustering se produit chaque fois que vous avez une pile de linge et que vous devez trier les v√™tements des membres de votre famille üß¶üëïüëñü©≤. En science des donn√©es, le clustering se produit lorsqu'on essaie d'analyser les pr√©f√©rences d'un utilisateur ou de d√©terminer les caract√©ristiques d'un ensemble de donn√©es non √©tiquet√©. Le clustering, d'une certaine mani√®re, aide √† donner un sens au chaos, comme un tiroir √† chaussettes.

[![Introduction au ML](https://img.youtube.com/vi/esmzYhuFnds/0.jpg)](https://youtu.be/esmzYhuFnds "Introduction au clustering")

> üé• Cliquez sur l'image ci-dessus pour une vid√©o : John Guttag du MIT introduit le clustering.

Dans un cadre professionnel, le clustering peut √™tre utilis√© pour d√©terminer des choses comme la segmentation de march√©, par exemple pour savoir quels groupes d'√¢ge ach√®tent quels articles. Une autre utilisation serait la d√©tection d'anomalies, peut-√™tre pour d√©tecter des fraudes dans un ensemble de donn√©es de transactions par carte de cr√©dit. Ou encore, vous pourriez utiliser le clustering pour identifier des tumeurs dans un lot de scans m√©dicaux.

‚úÖ Prenez une minute pour r√©fl√©chir √† la mani√®re dont vous avez pu rencontrer le clustering 'dans la nature', dans un contexte bancaire, e-commerce ou commercial.

> üéì Fait int√©ressant, l'analyse de clusters a vu le jour dans les domaines de l'anthropologie et de la psychologie dans les ann√©es 1930. Pouvez-vous imaginer comment elle aurait pu √™tre utilis√©e ?

Alternativement, vous pourriez l'utiliser pour regrouper des r√©sultats de recherche - par exemple des liens d'achat, des images ou des avis. Le clustering est utile lorsque vous avez un grand ensemble de donn√©es que vous souhaitez r√©duire et sur lequel vous voulez effectuer une analyse plus d√©taill√©e. Cette technique peut donc √™tre utilis√©e pour mieux comprendre les donn√©es avant de construire d'autres mod√®les.

‚úÖ Une fois vos donn√©es organis√©es en clusters, vous leur attribuez un identifiant de cluster. Cette technique peut √™tre utile pour pr√©server la confidentialit√© d'un ensemble de donn√©es ; vous pouvez alors vous r√©f√©rer √† un point de donn√©es par son identifiant de cluster, plut√¥t que par des donn√©es identifiables plus r√©v√©latrices. Pouvez-vous penser √† d'autres raisons pour lesquelles vous pr√©f√©reriez utiliser un identifiant de cluster plut√¥t que d'autres √©l√©ments du cluster pour l'identifier ?

Approfondissez votre compr√©hension des techniques de clustering dans ce [module d'apprentissage](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott).

## Premiers pas avec le clustering

[Scikit-learn propose une large gamme](https://scikit-learn.org/stable/modules/clustering.html) de m√©thodes pour effectuer du clustering. Le type que vous choisissez d√©pendra de votre cas d'utilisation. Selon la documentation, chaque m√©thode pr√©sente divers avantages. Voici un tableau simplifi√© des m√©thodes prises en charge par Scikit-learn et leurs cas d'utilisation appropri√©s :

| Nom de la m√©thode            | Cas d'utilisation                                                    |
| :--------------------------- | :------------------------------------------------------------------- |
| K-Means                      | usage g√©n√©ral, inductif                                              |
| Propagation d'affinit√©       | nombreux clusters, clusters in√©gaux, inductif                       |
| Mean-shift                   | nombreux clusters, clusters in√©gaux, inductif                       |
| Clustering spectral          | quelques clusters, clusters √©gaux, transductif                      |
| Clustering hi√©rarchique Ward | nombreux clusters contraints, transductif                           |
| Clustering agglom√©ratif      | nombreux clusters contraints, distances non euclidiennes, transductif |
| DBSCAN                       | g√©om√©trie non plate, clusters in√©gaux, transductif                  |
| OPTICS                       | g√©om√©trie non plate, clusters in√©gaux avec densit√© variable, transductif |
| M√©langes gaussiens           | g√©om√©trie plate, inductif                                            |
| BIRCH                        | grand ensemble de donn√©es avec des valeurs aberrantes, inductif     |

> üéì La mani√®re dont nous cr√©ons des clusters d√©pend beaucoup de la fa√ßon dont nous regroupons les points de donn√©es. D√©composons quelques notions :
>
> üéì ['Transductif' vs. 'inductif'](https://wikipedia.org/wiki/Transduction_(machine_learning))
> 
> L'inf√©rence transductive est d√©riv√©e des cas d'entra√Ænement observ√©s qui correspondent √† des cas de test sp√©cifiques. L'inf√©rence inductive est d√©riv√©e des cas d'entra√Ænement qui m√®nent √† des r√®gles g√©n√©rales, lesquelles sont ensuite appliqu√©es aux cas de test.
> 
> Un exemple : Imaginez que vous avez un ensemble de donn√©es partiellement √©tiquet√©. Certains √©l√©ments sont des 'disques', d'autres des 'CD', et certains sont non √©tiquet√©s. Votre t√¢che est de fournir des √©tiquettes pour les √©l√©ments non √©tiquet√©s. Si vous choisissez une approche inductive, vous entra√Æneriez un mod√®le en recherchant des 'disques' et des 'CD', et appliqueriez ces √©tiquettes aux donn√©es non √©tiquet√©es. Cette approche aurait du mal √† classer des √©l√©ments qui sont en r√©alit√© des 'cassettes'. Une approche transductive, en revanche, g√®re ces donn√©es inconnues plus efficacement en regroupant des √©l√©ments similaires et en appliquant une √©tiquette √† un groupe. Dans ce cas, les clusters pourraient refl√©ter 'objets musicaux ronds' et 'objets musicaux carr√©s'.
> 
> üéì ['G√©om√©trie non plate' vs. 'plate'](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)
> 
> Tir√©e de la terminologie math√©matique, la g√©om√©trie non plate vs. plate fait r√©f√©rence √† la mesure des distances entre les points par des m√©thodes g√©om√©triques 'plates' ([euclidiennes](https://wikipedia.org/wiki/G%C3%A9om%C3%A9trie_euclidienne)) ou 'non plates' (non euclidiennes).
>
>'Plate' dans ce contexte fait r√©f√©rence √† la g√©om√©trie euclidienne (dont certaines parties sont enseign√©es comme g√©om√©trie 'plane'), et 'non plate' fait r√©f√©rence √† la g√©om√©trie non euclidienne. Quel est le lien entre la g√©om√©trie et l'apprentissage automatique ? Eh bien, en tant que deux domaines enracin√©s dans les math√©matiques, il doit y avoir une mani√®re commune de mesurer les distances entre les points dans les clusters, et cela peut √™tre fait de mani√®re 'plate' ou 'non plate', selon la nature des donn√©es. Les [distances euclidiennes](https://wikipedia.org/wiki/Distance_euclidienne) sont mesur√©es comme la longueur d'un segment de ligne entre deux points. Les [distances non euclidiennes](https://wikipedia.org/wiki/G%C3%A9om%C3%A9trie_non_euclidienne) sont mesur√©es le long d'une courbe. Si vos donn√©es, visualis√©es, semblent ne pas exister sur un plan, vous pourriez avoir besoin d'utiliser un algorithme sp√©cialis√© pour les traiter.
>
![Infographie G√©om√©trie Plate vs Non Plate](../../../../translated_images/flat-nonflat.d1c8c6e2a96110c1d57fa0b72913f6aab3c245478524d25baf7f4a18efcde224.fr.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)
> 
> üéì ['Distances'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)
> 
> Les clusters sont d√©finis par leur matrice de distances, c'est-√†-dire les distances entre les points. Cette distance peut √™tre mesur√©e de plusieurs fa√ßons. Les clusters euclidiens sont d√©finis par la moyenne des valeurs des points et contiennent un 'centro√Øde' ou point central. Les distances sont donc mesur√©es par rapport √† ce centro√Øde. Les distances non euclidiennes font r√©f√©rence aux 'clustro√Ødes', le point le plus proche des autres points. Les clustro√Ødes peuvent √† leur tour √™tre d√©finis de diff√©rentes mani√®res.
> 
> üéì ['Contraint'](https://wikipedia.org/wiki/Constrained_clustering)
> 
> Le [clustering contraint](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) introduit l'apprentissage 'semi-supervis√©' dans cette m√©thode non supervis√©e. Les relations entre les points sont marqu√©es comme 'ne peut pas lier' ou 'doit lier', ce qui impose certaines r√®gles √† l'ensemble de donn√©es.
>
>Un exemple : Si un algorithme est laiss√© libre sur un lot de donn√©es non √©tiquet√©es ou semi-√©tiquet√©es, les clusters qu'il produit peuvent √™tre de mauvaise qualit√©. Dans l'exemple ci-dessus, les clusters pourraient regrouper 'objets musicaux ronds', 'objets musicaux carr√©s', 'objets triangulaires' et 'biscuits'. Si on lui donne des contraintes ou des r√®gles √† suivre ("l'objet doit √™tre en plastique", "l'objet doit pouvoir produire de la musique"), cela peut aider √† 'contraindre' l'algorithme √† faire de meilleurs choix.
> 
> üéì 'Densit√©'
> 
> Les donn√©es 'bruyantes' sont consid√©r√©es comme 'denses'. Les distances entre les points dans chacun de ses clusters peuvent s'av√©rer, apr√®s examen, plus ou moins denses, ou 'concentr√©es', et ces donn√©es doivent donc √™tre analys√©es avec la m√©thode de clustering appropri√©e. [Cet article](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) montre la diff√©rence entre l'utilisation du clustering K-Means et des algorithmes HDBSCAN pour explorer un ensemble de donn√©es bruyant avec une densit√© de cluster in√©gale.

## Algorithmes de clustering

Il existe plus de 100 algorithmes de clustering, et leur utilisation d√©pend de la nature des donn√©es disponibles. Discutons de quelques-uns des principaux :

- **Clustering hi√©rarchique**. Si un objet est class√© par sa proximit√© avec un objet voisin, plut√¥t qu'avec un objet plus √©loign√©, les clusters sont form√©s en fonction de la distance de leurs membres par rapport aux autres objets. Le clustering agglom√©ratif de Scikit-learn est hi√©rarchique.

   ![Infographie Clustering Hi√©rarchique](../../../../translated_images/hierarchical.bf59403aa43c8c47493bfdf1cc25230f26e45f4e38a3d62e8769cd324129ac15.fr.png)
   > Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Clustering par centro√Øde**. Cet algorithme populaire n√©cessite de choisir 'k', ou le nombre de clusters √† former, apr√®s quoi l'algorithme d√©termine le point central d'un cluster et regroupe les donn√©es autour de ce point. Le [clustering K-means](https://wikipedia.org/wiki/K-means_clustering) est une version populaire du clustering par centro√Øde. Le centre est d√©termin√© par la moyenne la plus proche, d'o√π son nom. La distance au cluster est minimis√©e.

   ![Infographie Clustering par Centro√Øde](../../../../translated_images/centroid.097fde836cf6c9187d0b2033e9f94441829f9d86f4f0b1604dd4b3d1931aee34.fr.png)
   > Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Clustering bas√© sur la distribution**. Bas√© sur la mod√©lisation statistique, le clustering bas√© sur la distribution se concentre sur la d√©termination de la probabilit√© qu'un point de donn√©es appartienne √† un cluster, et l'y attribue en cons√©quence. Les m√©thodes de m√©lange gaussien appartiennent √† ce type.

- **Clustering bas√© sur la densit√©**. Les points de donn√©es sont attribu√©s √† des clusters en fonction de leur densit√©, ou de leur regroupement les uns autour des autres. Les points de donn√©es √©loign√©s du groupe sont consid√©r√©s comme des valeurs aberrantes ou du bruit. DBSCAN, Mean-shift et OPTICS appartiennent √† ce type de clustering.

- **Clustering bas√© sur une grille**. Pour les ensembles de donn√©es multidimensionnels, une grille est cr√©√©e et les donn√©es sont r√©parties entre les cellules de la grille, cr√©ant ainsi des clusters.

## Exercice - regroupez vos donn√©es

Le clustering en tant que technique est grandement facilit√© par une bonne visualisation, alors commen√ßons par visualiser nos donn√©es musicales. Cet exercice nous aidera √† d√©cider quelle m√©thode de clustering utiliser le plus efficacement en fonction de la nature de ces donn√©es.

1. Ouvrez le fichier [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/notebook.ipynb) dans ce dossier.

1. Importez le package `Seaborn` pour une bonne visualisation des donn√©es.

    ```python
    !pip install seaborn
    ```

1. Ajoutez les donn√©es des chansons √† partir de [_nigerian-songs.csv_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/data/nigerian-songs.csv). Chargez un dataframe avec des donn√©es sur les chansons. Pr√©parez-vous √† explorer ces donn√©es en important les biblioth√®ques et en affichant les donn√©es :

    ```python
    import matplotlib.pyplot as plt
    import pandas as pd
    
    df = pd.read_csv("../data/nigerian-songs.csv")
    df.head()
    ```

    V√©rifiez les premi√®res lignes de donn√©es :

    |     | nom                     | album                        | artiste              | genre_principal_artiste | date_sortie | dur√©e | popularit√© | dansabilit√© | acoustique | √©nergie | instrumentalit√© | vivacit√© | volume   | discours    | tempo   | signature_temps |
    | --- | ------------------------ | ---------------------------- | -------------------- | ----------------------- | ------------ | ------ | ---------- | ----------- | ---------- | ------- | --------------- | -------- | -------- | ----------- | ------- | -------------- |
    | 0   | Sparky                   | Mandy & The Jungle           | Cruel Santino        | r&b alternatif          | 2019         | 144000 | 48         | 0.666       | 0.851      | 0.42    | 0.534           | 0.11     | -6.699   | 0.0829      | 133.015 | 5              |
    | 1   | shuga rush               | EVERYTHING YOU HEARD IS TRUE | Odunsi (The Engine)  | afropop                 | 2020         | 89488  | 30         | 0.71        | 0.0822     | 0.683   | 0.000169        | 0.101    | -5.64    | 0.36        | 129.993 | 3              |
| 2   | LITT!                    | LITT!                        | AYL√ò                | indie r&b        | 2018         | 207758 | 40         | 0.836        | 0.272        | 0.564  | 0.000537         | 0.11     | -7.127   | 0.0424      | 130.005 | 4              |
| 3   | Confident / Feeling Cool | Enjoy Your Life              | Lady Donli          | nigerian pop     | 2019         | 175135 | 14         | 0.894        | 0.798        | 0.611  | 0.000187         | 0.0964   | -4.961   | 0.113       | 111.087 | 4              |
| 4   | wanted you               | rare.                        | Odunsi (The Engine) | afropop          | 2018         | 152049 | 25         | 0.702        | 0.116        | 0.833  | 0.91             | 0.348    | -6.044   | 0.0447      | 105.115 | 4              |

1. Obtenez des informations sur le dataframe en appelant `info()` :

    ```python
    df.info()
    ```

   Le r√©sultat ressemble √† ceci :

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 530 entries, 0 to 529
    Data columns (total 16 columns):
     #   Column            Non-Null Count  Dtype  
    ---  ------            --------------  -----  
     0   name              530 non-null    object 
     1   album             530 non-null    object 
     2   artist            530 non-null    object 
     3   artist_top_genre  530 non-null    object 
     4   release_date      530 non-null    int64  
     5   length            530 non-null    int64  
     6   popularity        530 non-null    int64  
     7   danceability      530 non-null    float64
     8   acousticness      530 non-null    float64
     9   energy            530 non-null    float64
     10  instrumentalness  530 non-null    float64
     11  liveness          530 non-null    float64
     12  loudness          530 non-null    float64
     13  speechiness       530 non-null    float64
     14  tempo             530 non-null    float64
     15  time_signature    530 non-null    int64  
    dtypes: float64(8), int64(4), object(4)
    memory usage: 66.4+ KB
    ```

1. V√©rifiez les valeurs nulles en appelant `isnull()` et en v√©rifiant que la somme est √©gale √† 0 :

    ```python
    df.isnull().sum()
    ```

    Tout semble correct :

    ```output
    name                0
    album               0
    artist              0
    artist_top_genre    0
    release_date        0
    length              0
    popularity          0
    danceability        0
    acousticness        0
    energy              0
    instrumentalness    0
    liveness            0
    loudness            0
    speechiness         0
    tempo               0
    time_signature      0
    dtype: int64
    ```

1. D√©crivez les donn√©es :

    ```python
    df.describe()
    ```

    |       | release_date | length      | popularity | danceability | acousticness | energy   | instrumentalness | liveness | loudness  | speechiness | tempo      | time_signature |
    | ----- | ------------ | ----------- | ---------- | ------------ | ------------ | -------- | ---------------- | -------- | --------- | ----------- | ---------- | -------------- |
    | count | 530          | 530         | 530        | 530          | 530          | 530      | 530              | 530      | 530       | 530         | 530        | 530            |
    | mean  | 2015.390566  | 222298.1698 | 17.507547  | 0.741619     | 0.265412     | 0.760623 | 0.016305         | 0.147308 | -4.953011 | 0.130748    | 116.487864 | 3.986792       |
    | std   | 3.131688     | 39696.82226 | 18.992212  | 0.117522     | 0.208342     | 0.148533 | 0.090321         | 0.123588 | 2.464186  | 0.092939    | 23.518601  | 0.333701       |
    | min   | 1998         | 89488       | 0          | 0.255        | 0.000665     | 0.111    | 0                | 0.0283   | -19.362   | 0.0278      | 61.695     | 3              |
    | 25%   | 2014         | 199305      | 0          | 0.681        | 0.089525     | 0.669    | 0                | 0.07565  | -6.29875  | 0.0591      | 102.96125  | 4              |
    | 50%   | 2016         | 218509      | 13         | 0.761        | 0.2205       | 0.7845   | 0.000004         | 0.1035   | -4.5585   | 0.09795     | 112.7145   | 4              |
    | 75%   | 2017         | 242098.5    | 31         | 0.8295       | 0.403        | 0.87575  | 0.000234         | 0.164    | -3.331    | 0.177       | 125.03925  | 4              |
    | max   | 2020         | 511738      | 73         | 0.966        | 0.954        | 0.995    | 0.91             | 0.811    | 0.582     | 0.514       | 206.007    | 5              |

> ü§î Si nous travaillons avec le clustering, une m√©thode non supervis√©e qui ne n√©cessite pas de donn√©es √©tiquet√©es, pourquoi montrons-nous ces donn√©es avec des √©tiquettes ? Lors de la phase d'exploration des donn√©es, elles sont utiles, mais elles ne sont pas n√©cessaires pour que les algorithmes de clustering fonctionnent. Vous pourriez tout aussi bien supprimer les en-t√™tes de colonnes et vous r√©f√©rer aux donn√©es par num√©ro de colonne.

Regardez les valeurs g√©n√©rales des donn√©es. Notez que la popularit√© peut √™tre '0', ce qui montre des chansons sans classement. Supprimons ces donn√©es bient√¥t.

1. Utilisez un barplot pour d√©couvrir les genres les plus populaires :

    ```python
    import seaborn as sns
    
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top[:5].index,y=top[:5].values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    ![most popular](../../../../translated_images/popular.9c48d84b3386705f98bf44e26e9655bee9eb7c849d73be65195e37895bfedb5d.fr.png)

‚úÖ Si vous souhaitez voir plus de valeurs en haut du classement, modifiez le top `[:5]` pour une valeur plus grande ou supprimez-le pour voir tout.

Notez que lorsque le genre principal est d√©crit comme 'Missing', cela signifie que Spotify ne l'a pas classifi√©. Supprimons-le.

1. Supprimez les donn√©es manquantes en les filtrant :

    ```python
    df = df[df['artist_top_genre'] != 'Missing']
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    Re-v√©rifiez maintenant les genres :

    ![most popular](../../../../translated_images/all-genres.1d56ef06cefbfcd61183023834ed3cb891a5ee638a3ba5c924b3151bf80208d7.fr.png)

1. Les trois genres principaux dominent largement ce dataset. Concentrons-nous sur `afro dancehall`, `afropop` et `nigerian pop`, et filtrons √©galement le dataset pour supprimer tout ce qui a une valeur de popularit√© √©gale √† 0 (ce qui signifie qu'il n'a pas √©t√© class√© dans le dataset et peut √™tre consid√©r√© comme du bruit pour nos objectifs) :

    ```python
    df = df[(df['artist_top_genre'] == 'afro dancehall') | (df['artist_top_genre'] == 'afropop') | (df['artist_top_genre'] == 'nigerian pop')]
    df = df[(df['popularity'] > 0)]
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

1. Faites un test rapide pour voir si les donn√©es pr√©sentent une corr√©lation particuli√®rement forte :

    ```python
    corrmat = df.corr(numeric_only=True)
    f, ax = plt.subplots(figsize=(12, 9))
    sns.heatmap(corrmat, vmax=.8, square=True)
    ```

    ![correlations](../../../../translated_images/correlation.a9356bb798f5eea51f47185968e1ebac5c078c92fce9931e28ccf0d7fab71c2b.fr.png)

    La seule corr√©lation forte est entre `energy` et `loudness`, ce qui n'est pas tr√®s surprenant, √©tant donn√© que la musique forte est g√©n√©ralement assez √©nergique. Sinon, les corr√©lations sont relativement faibles. Il sera int√©ressant de voir ce qu'un algorithme de clustering peut tirer de ces donn√©es.

    > üéì Notez que la corr√©lation n'implique pas la causalit√© ! Nous avons une preuve de corr√©lation mais aucune preuve de causalit√©. Un [site web amusant](https://tylervigen.com/spurious-correlations) propose des visuels qui soulignent ce point.

Y a-t-il une convergence dans ce dataset autour de la popularit√© per√ßue d'une chanson et de sa capacit√© √† faire danser ? Une FacetGrid montre qu'il existe des cercles concentriques qui s'alignent, quel que soit le genre. Est-il possible que les go√ªts nig√©rians convergent √† un certain niveau de capacit√© √† faire danser pour ce genre ?  

‚úÖ Essayez diff√©rents points de donn√©es (√©nergie, loudness, speechiness) et plus ou diff√©rents genres musicaux. Que pouvez-vous d√©couvrir ? Consultez le tableau `df.describe()` pour voir la r√©partition g√©n√©rale des points de donn√©es.

### Exercice - distribution des donn√©es

Ces trois genres sont-ils significativement diff√©rents dans la perception de leur capacit√© √† faire danser, en fonction de leur popularit√© ?

1. Examinez la distribution des donn√©es de nos trois genres principaux pour la popularit√© et la capacit√© √† faire danser le long d'un axe x et y donn√©.

    ```python
    sns.set_theme(style="ticks")
    
    g = sns.jointplot(
        data=df,
        x="popularity", y="danceability", hue="artist_top_genre",
        kind="kde",
    )
    ```

    Vous pouvez d√©couvrir des cercles concentriques autour d'un point de convergence g√©n√©ral, montrant la distribution des points.

    > üéì Notez que cet exemple utilise un graphique KDE (Kernel Density Estimate) qui repr√©sente les donn√©es √† l'aide d'une courbe de densit√© de probabilit√© continue. Cela nous permet d'interpr√©ter les donn√©es lorsque nous travaillons avec plusieurs distributions.

    En g√©n√©ral, les trois genres s'alignent vaguement en termes de popularit√© et de capacit√© √† faire danser. D√©terminer des clusters dans ces donn√©es faiblement align√©es sera un d√©fi :

    ![distribution](../../../../translated_images/distribution.9be11df42356ca958dc8e06e87865e09d77cab78f94fe4fea8a1e6796c64dc4b.fr.png)

1. Cr√©ez un scatter plot :

    ```python
    sns.FacetGrid(df, hue="artist_top_genre", height=5) \
       .map(plt.scatter, "popularity", "danceability") \
       .add_legend()
    ```

    Un scatter plot des m√™mes axes montre un sch√©ma similaire de convergence.

    ![Facetgrid](../../../../translated_images/facetgrid.9b2e65ce707eba1f983b7cdfed5d952e60f385947afa3011df6e3cc7d200eb5b.fr.png)

En g√©n√©ral, pour le clustering, vous pouvez utiliser des scatter plots pour montrer des clusters de donn√©es, donc ma√Ætriser ce type de visualisation est tr√®s utile. Dans la prochaine le√ßon, nous utiliserons ces donn√©es filtr√©es et appliquerons le clustering k-means pour d√©couvrir des groupes dans ces donn√©es qui semblent se chevaucher de mani√®re int√©ressante.

---

## üöÄD√©fi

En pr√©paration de la prochaine le√ßon, cr√©ez un tableau sur les diff√©rents algorithmes de clustering que vous pourriez d√©couvrir et utiliser dans un environnement de production. Quels types de probl√®mes le clustering cherche-t-il √† r√©soudre ?

## [Quiz post-lecture](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)

## R√©vision et auto-apprentissage

Avant d'appliquer des algorithmes de clustering, comme nous l'avons appris, il est judicieux de comprendre la nature de votre dataset. Lisez-en davantage sur ce sujet [ici](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)

[Cet article utile](https://www.freecodecamp.org/news/8-clustering-algorithms-in-machine-learning-that-all-data-scientists-should-know/) vous guide √† travers les diff√©rentes fa√ßons dont divers algorithmes de clustering se comportent, en fonction des formes des donn√©es.

## Devoir

[Recherchez d'autres visualisations pour le clustering](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.